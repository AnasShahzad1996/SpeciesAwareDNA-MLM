{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9xlU-UNDF1nu"
      },
      "source": [
        "# Notebook ML4RG-Project\n",
        "\n",
        "First download the data and install the needed packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yaxJnR293QS",
        "outputId": "31a59cc9-2725-4c1a-9baa-6b62cb084811"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ML4RG-2023-project'...\n",
            "remote: Enumerating objects: 402, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 402 (delta 13), reused 6 (delta 4), pack-reused 381\u001b[K\n",
            "Receiving objects: 100% (402/402), 9.86 MiB | 15.36 MiB/s, done.\n",
            "Resolving deltas: 100% (220/220), done.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16BUHUYXNYvndfsiECB8-C7cwWq82oTg-\n",
            "To: /content/ML4RG-2023-project.tar\n",
            "100% 39.8M/39.8M [00:00<00:00, 116MB/s] \n"
          ]
        }
      ],
      "source": [
        "![[ ! -d ML4RG-2023-project ]] && git clone https://github.com/Hugenotte585/ML4RG-2023-project.git\n",
        "!gdown https://drive.google.com/uc?id=16BUHUYXNYvndfsiECB8-C7cwWq82oTg-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuNw_UyuFKxm",
        "outputId": "f713ff6b-fe83-4ed2-b0df-d1529a1c5efe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Homo_sapiens_3prime_UTR.fa\n",
            "Homo_sapiens_3prime_UTR.fa.fai\n",
            "MLM_mammals_species_aware_5000_weights\n"
          ]
        }
      ],
      "source": [
        "!tar -xvf ML4RG-2023-project.tar\n",
        "!rm ML4RG-2023-project.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfS38pRC-HV7",
        "outputId": "8ef66fea-5e2c-49e9-e0ca-f262eaa787b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install pysam\n",
        "!pip -q install torchmetrics\n",
        "!pip -q install einops\n",
        "!pip -q install omegaconf\n",
        "!pip -q install biopython\n",
        "!pip -q install logomaker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1TK2pn7T85z5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "colab = True\n",
        "import sys, os\n",
        "if colab:\n",
        "    sys.path.insert(0, './ML4RG-2023-project')\n",
        "else:\n",
        "    sys.path.insert(0, '..')\n",
        "\n",
        "\n",
        "import gc\n",
        "import pysam\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import helpers.train_eval as train_eval    #train and evaluation\n",
        "import helpers.misc as misc                #miscellaneous functions\n",
        "\n",
        "import encoding_utils.sequence_encoders as sequence_encoders\n",
        "import encoding_utils.sequence_utils as sequence_utils\n",
        "from models.spec_dss import DSSResNet, DSSResNetEmb, SpecAdd\n",
        "from models.baseline.markov_model import *\n",
        "from models.baseline.markov_for_dinuc import *\n",
        "from Bio import SeqIO\n",
        "import pickle\n",
        "import glob"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W1qMFGvrN3AB"
      },
      "source": [
        "Example script usage ^^"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfBjjIh4M1_R"
      },
      "outputs": [],
      "source": [
        "#!cd ML4RG-2023-project && python main.py --test --fasta ../Homo_sapiens_3prime_UTR.fa --species_list 240_species.txt --output_dir ./test --model_weight ../MLM_mammals_species_aware_5000_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LL9tNZ8ZXFmx",
        "outputId": "f3613a29-e0b2-4226-ecf9-a9b5e22b84ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2tttZdnW-U7",
        "outputId": "06f18d0f-d276-4999-ca48-9e696e16194e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/content/prbs.pt': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!cp -r \"/content/prbs.pt\" \"/content/drive/MyDrive/MLRG2023\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ICQqqx0TuOn6"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "species_agnostic = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lhoDjF_QtiFg"
      },
      "outputs": [],
      "source": [
        "class SeqDataset(Dataset):\n",
        "\n",
        "    def __init__(self, fasta_fa, seq_df, transform, motifs):\n",
        "\n",
        "        self.fasta = pysam.FastaFile(fasta_fa)\n",
        "\n",
        "        self.val_fraction = 0.1\n",
        "        N_train = int(len(seq_df) * (1-self.val_fraction))\n",
        "        self.start_index = N_train\n",
        "        self.seq_df = seq_df\n",
        "        self.transform = transform\n",
        "\n",
        "        self.motifs = motifs\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.seq_df[self.start_index:])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      seq = self.fasta.fetch(self.seq_df.iloc[self.start_index + idx].seq_name).upper()\n",
        "        #print(seq)\n",
        "      species_label = self.seq_df.iloc[self.start_index + idx].species_label\n",
        "        #print(species_label)\n",
        "        # x_batch, y_masked_batch, y_batch, mask_batch, motif_mask_batch\n",
        "      masked_sequence, target_labels_masked, target_labels, mask, motif_mask_batch = self.transform(seq, motifs = self.motifs)\n",
        "\n",
        "      masked_sequence = (masked_sequence, species_label)\n",
        "      return masked_sequence, target_labels_masked, target_labels, motif_mask_batch\n",
        "\n",
        "    def close(self):\n",
        "      self.fasta.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pn3Q2CT9Cco5"
      },
      "source": [
        "# Read the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "JpuvZdcct_iW",
        "outputId": "4d55c12b-496f-4cac-bf86-3ea576de1249"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seq_name</th>\n",
              "      <th>species_name</th>\n",
              "      <th>species_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENST00000641515.2_utr3_2_0_chr1_70009_f:Homo_s...</td>\n",
              "      <td>Homo_sapiens</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENST00000616016.5_utr3_13_0_chr1_944154_f:Homo...</td>\n",
              "      <td>Homo_sapiens</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENST00000327044.7_utr3_18_0_chr1_944203_r:Homo...</td>\n",
              "      <td>Homo_sapiens</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENST00000338591.8_utr3_11_0_chr1_965192_f:Homo...</td>\n",
              "      <td>Homo_sapiens</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENST00000379410.8_utr3_15_0_chr1_974576_f:Homo...</td>\n",
              "      <td>Homo_sapiens</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18129</th>\n",
              "      <td>ENST00000303766.12_utr3_11_0_chrY_22168542_r:H...</td>\n",
              "      <td>Homo_sapiens</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18130</th>\n",
              "      <td>ENST00000250831.6_utr3_11_0_chrY_22417604_f:Ho...</td>\n",
              "      <td>Homo_sapiens</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18131</th>\n",
              "      <td>ENST00000303728.5_utr3_4_0_chrY_22514071_f:Hom...</td>\n",
              "      <td>Homo_sapiens</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18132</th>\n",
              "      <td>ENST00000382407.1_utr3_0_0_chrY_24045793_r:Hom...</td>\n",
              "      <td>Homo_sapiens</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18133</th>\n",
              "      <td>ENST00000306609.5_utr3_1_0_chrY_25624528_f:Hom...</td>\n",
              "      <td>Homo_sapiens</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18134 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                seq_name  species_name  \\\n",
              "0      ENST00000641515.2_utr3_2_0_chr1_70009_f:Homo_s...  Homo_sapiens   \n",
              "1      ENST00000616016.5_utr3_13_0_chr1_944154_f:Homo...  Homo_sapiens   \n",
              "2      ENST00000327044.7_utr3_18_0_chr1_944203_r:Homo...  Homo_sapiens   \n",
              "3      ENST00000338591.8_utr3_11_0_chr1_965192_f:Homo...  Homo_sapiens   \n",
              "4      ENST00000379410.8_utr3_15_0_chr1_974576_f:Homo...  Homo_sapiens   \n",
              "...                                                  ...           ...   \n",
              "18129  ENST00000303766.12_utr3_11_0_chrY_22168542_r:H...  Homo_sapiens   \n",
              "18130  ENST00000250831.6_utr3_11_0_chrY_22417604_f:Ho...  Homo_sapiens   \n",
              "18131  ENST00000303728.5_utr3_4_0_chrY_22514071_f:Hom...  Homo_sapiens   \n",
              "18132  ENST00000382407.1_utr3_0_0_chrY_24045793_r:Hom...  Homo_sapiens   \n",
              "18133  ENST00000306609.5_utr3_1_0_chrY_25624528_f:Hom...  Homo_sapiens   \n",
              "\n",
              "       species_label  \n",
              "0                181  \n",
              "1                181  \n",
              "2                181  \n",
              "3                181  \n",
              "4                181  \n",
              "...              ...  \n",
              "18129            181  \n",
              "18130            181  \n",
              "18131            181  \n",
              "18132            181  \n",
              "18133            181  \n",
              "\n",
              "[18134 rows x 3 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fasta_fa = \"./Homo_sapiens_3prime_UTR.fa\"\n",
        "if not colab:\n",
        "    fasta_fa = glob.glob(\"../../test/*.fa\")[0]\n",
        "species_list = \"ML4RG-2023-project/240_species.txt\"\n",
        "if not colab:\n",
        "    species_list = \"../240_species.txt\"\n",
        "seq_df = pd.read_csv(fasta_fa + '.fai', header=None, sep='\\t', usecols=[0], names=['seq_name'])\n",
        "seq_df['species_name'] = seq_df.seq_name.apply(lambda x:x.split(':')[1])\n",
        "species_encoding = pd.read_csv(species_list, header=None).squeeze().to_dict()\n",
        "\n",
        "if not species_agnostic:\n",
        "    species_encoding = {species:idx for idx,species in species_encoding.items()}\n",
        "else:\n",
        "    species_encoding = {species:0 for _,species in species_encoding.items()}\n",
        "\n",
        "species_encoding['Homo_sapiens'] = species_encoding['Pan_troglodytes']\n",
        "seq_df['species_label'] = seq_df.species_name.map(species_encoding)\n",
        "\n",
        "seq_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "R-vMMPNsDE47"
      },
      "outputs": [],
      "source": [
        "# Motif:id\n",
        "motifs = {\"GTATG\":1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW5WHLHLuWYs",
        "outputId": "2b160d92-d065-48ab-d325-00b100a5855a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1814"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kseq_len = 5000\n",
        "total_len = 5000\n",
        "\n",
        "seq_transform = sequence_encoders.RollingMasker()\n",
        "\n",
        "test_dataset = SeqDataset(fasta_fa, seq_df, transform = seq_transform, motifs=motifs)\n",
        "test_dataloader = DataLoader(dataset = test_dataset, batch_size = 1, num_workers = 1, collate_fn = None, shuffle = False)\n",
        "len(test_dataset)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "niH8MWiYHOh5"
      },
      "source": [
        "# Load the model\n",
        "## Model params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBXfcF0ism6L",
        "outputId": "f68ca81b-4592-4205-896a-85e92fe100e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "m7CXRV-Iu0vT"
      },
      "outputs": [],
      "source": [
        "d_model = 128\n",
        "n_layers = 4\n",
        "dropout = 0.\n",
        "learn_rate = 1e-4\n",
        "weight_decay = 0.\n",
        "output_dir = \"./test/\"\n",
        "get_embeddings = True\n",
        "save_at = None\n",
        "\n",
        "species_encoder = SpecAdd(embed = True, encoder = 'label', d_model = 128)\n",
        "\n",
        "model = DSSResNetEmb(d_input = 5, d_output = 5, d_model = d_model, n_layers = n_layers,\n",
        "                     dropout = dropout, embed_before = True, species_encoder = species_encoder)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "model_params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "optimizer = torch.optim.Adam(model_params, lr = learn_rate, weight_decay = weight_decay)\n",
        "\n",
        "last_epoch = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipDi-5piwZrL",
        "outputId": "7b2f837a-bc2f-4254-fc53-1ba9ed53cd4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "species_agnostic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrddJYZ9u8zI",
        "outputId": "b4cfcd1b-5b9c-4715-dc1c-dd21a6bcb8fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if not species_agnostic:\n",
        "    model_weight = \"MLM_mammals_species_aware_5000_weights\"\n",
        "else :\n",
        "    model_weight = \"MLM_mammals_species_agnostic_5000_weights\"\n",
        "# load model but avoid torch._C._cuda_getDeviceCount() > 0 failed error\n",
        "model.load_state_dict(torch.load(model_weight, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QSzrD5xrwl7a"
      },
      "outputs": [],
      "source": [
        "predictions_dir = os.path.join(output_dir, 'predictions') #dir to save predictions\n",
        "weights_dir = os.path.join(output_dir, 'weights') #dir to save model weights at save_at epochs\n",
        "if save_at:\n",
        "    os.makedirs(weights_dir, exist_ok = True)\n",
        "\n",
        "def metrics_to_str(metrics):\n",
        "    loss, total_acc, masked_acc = metrics\n",
        "    return f'loss: {loss:.4}, total acc: {total_acc:.3f}, masked acc: {masked_acc:.3f}'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1aIpGqFHaZY"
      },
      "source": [
        "## Model\n",
        "If the following line fails:\n",
        "\n",
        "```\n",
        "model = model.to(device)\n",
        "```\n",
        "Either use:\n",
        "\n",
        "\n",
        "```\n",
        "device = torch.device(\"cpu\")\n",
        "```\n",
        "Or go to Runtime -> change runtime type -> Hardware Accellerator 'GPU'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3e2OK0W7wscx"
      },
      "outputs": [],
      "source": [
        "from helpers.metrics import MaskedAccuracy\n",
        "def model_eval_check(model, optimizer, dataloader, device, get_embeddings = False, silent=False):\n",
        "    criterion = torch.nn.CrossEntropyLoss(reduction = \"mean\")\n",
        "\n",
        "    metric = MaskedAccuracy().to(device)\n",
        "    motif_metric = MaskedAccuracy().to(device)\n",
        "\n",
        "    model.eval() #model to train mode\n",
        "\n",
        "    if not silent:\n",
        "        tot_itr = len(dataloader.dataset)//dataloader.batch_size #total train iterations\n",
        "        pbar = tqdm(total = tot_itr, ncols=700) #progress bar\n",
        "\n",
        "    avg_loss, masked_acc, total_acc = 0., 0., 0.\n",
        "\n",
        "    all_embeddings = []\n",
        "    outputs = []\n",
        "    with torch.no_grad():\n",
        "      for itr_idx, (((masked_sequence, species_label), targets_masked, targets, motif_mask)) in enumerate(dataloader):\n",
        "\n",
        "            if get_embeddings:\n",
        "                #batches are generated by transformation in the dataset,\n",
        "                #so remove extra batch dimension added by dataloader\n",
        "                masked_sequence, targets_masked, targets = masked_sequence[0], targets_masked[0], targets[0]\n",
        "                species_label = species_label.tile((len(masked_sequence),))\n",
        "\n",
        "            masked_sequence = masked_sequence.to(device)\n",
        "            targets_masked = targets_masked.to(device)\n",
        "\n",
        "            motif_targets=targets.detach().clone()\n",
        "            motif_targets[motif_mask.squeeze()== 0] = -100.0\n",
        "            print(f\"{itr_idx}: {motif_targets.shape}\")\n",
        "            motif_targets[targets_masked == -100] = -100.0\n",
        "            targets = targets.to(device)\n",
        "            species_label = torch.tensor(species_label).long().to(device)\n",
        "\n",
        "            logits, embeddings = model(masked_sequence, species_label)\n",
        "\n",
        "            loss = criterion(logits, targets_masked)\n",
        "            avg_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            preds = preds.to(device)\n",
        "            motif_targets = motif_targets.to(device)\n",
        "\n",
        "\n",
        "            test_acc_motif = motif_metric(preds, motif_targets)\n",
        "            masked_acc += metric(preds, targets_masked).detach() # compute only on masked nucleotides\n",
        "            total_acc += metric(preds, targets).detach()\n",
        "            #print(masked_acc/(itr_idx+1))\n",
        "\n",
        "            if get_embeddings:\n",
        "                # only get embeddings of the masked nucleotide\n",
        "                sequence_embedding = embeddings[\"seq_embedding\"]\n",
        "                sequence_embedding = sequence_embedding.transpose(-1,-2)[targets_masked!=-100]\n",
        "                # shape # B, L, dim  to L,dim, left with only masked nucleotide embeddings\n",
        "                # average over sequence\n",
        "                #print(sequence_embedding.shape)\n",
        "                sequence_embedding = sequence_embedding.mean(dim=0) # if we mask\n",
        "                #sequence_embedding = sequence_embedding[0].mean(dim=-1) # no mask\n",
        "\n",
        "                sequence_embedding = sequence_embedding.detach().cpu().numpy()\n",
        "                all_embeddings.append(sequence_embedding)\n",
        "            if not silent:\n",
        "                pbar.update(1)\n",
        "                pbar.set_description(f\"acc: {total_acc/(itr_idx+1):.2}, masked acc: {masked_acc/(itr_idx+1):.2}, motif acc {test_acc_motif/(itr_idx+1):.2} loss: {avg_loss/(itr_idx+1):.4}\")\n",
        "            outputs.append({\"loss\": loss, \"preds\": preds, \"logits\": logits, \"targets\": targets_masked, \"motifs\": motif_mask})\n",
        "    if not silent:\n",
        "        del pbar\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Nht-fx2ew8P-",
        "outputId": "5edf8763-321d-466c-dd16-22735599f81e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: torch.Size([30, 4956])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-16-d267222db115>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  species_label = torch.tensor(species_label).long().to(device)\n",
            "/content/./ML4RG-2023-project/models/dss.py:335: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at ../aten/src/ATen/native/Copy.cpp:276.)\n",
            "  return einsum('chn,hnl->chl', W, S).float(), state                   # [C H L]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1338: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.\n",
            "  warnings.warn(\"dropout2d: Received a 3D input to dropout2d and assuming that channel-wise \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1: torch.Size([30, 1214])\n",
            "2: torch.Size([30, 892])\n",
            "3: torch.Size([30, 511])\n",
            "4: torch.Size([30, 504])\n",
            "5: torch.Size([30, 555])\n",
            "6: torch.Size([30, 2448])\n",
            "7: torch.Size([30, 2522])\n",
            "8: torch.Size([30, 6014])\n",
            "9: torch.Size([30, 2441])\n",
            "10: torch.Size([30, 891])\n",
            "11: torch.Size([30, 2879])\n",
            "12: torch.Size([30, 1550])\n",
            "13: torch.Size([30, 218])\n",
            "14: torch.Size([30, 154])\n",
            "15: torch.Size([30, 1021])\n",
            "16: torch.Size([30, 1276])\n",
            "17: torch.Size([30, 466])\n",
            "18: torch.Size([30, 5654])\n",
            "19: torch.Size([30, 777])\n",
            "20: torch.Size([30, 2377])\n",
            "21: torch.Size([30, 5823])\n",
            "22: torch.Size([30, 426])\n",
            "23: torch.Size([30, 3850])\n",
            "24: torch.Size([30, 1714])\n",
            "25: torch.Size([30, 594])\n",
            "26: torch.Size([30, 1518])\n",
            "27: torch.Size([30, 1907])\n",
            "28: torch.Size([30, 1101])\n",
            "29: torch.Size([30, 1656])\n",
            "30: torch.Size([30, 258])\n",
            "31: torch.Size([30, 1986])\n",
            "32: torch.Size([30, 2798])\n",
            "33: torch.Size([30, 126])\n",
            "34: torch.Size([30, 2245])\n",
            "35: torch.Size([30, 1003])\n",
            "36: torch.Size([30, 7883])\n",
            "37: torch.Size([30, 1511])\n",
            "38: torch.Size([30, 1162])\n",
            "39: torch.Size([30, 25])\n",
            "40: torch.Size([30, 2509])\n",
            "41: torch.Size([30, 5776])\n",
            "42: torch.Size([30, 2316])\n",
            "43: torch.Size([30, 2738])\n",
            "44: torch.Size([30, 2716])\n",
            "45: torch.Size([30, 3003])\n",
            "46: torch.Size([30, 3446])\n",
            "47: torch.Size([30, 2272])\n",
            "48: torch.Size([30, 941])\n",
            "49: torch.Size([30, 1284])\n",
            "50: torch.Size([30, 1178])\n",
            "51: torch.Size([30, 263])\n",
            "52: torch.Size([30, 3371])\n",
            "53: torch.Size([30, 6737])\n",
            "54: torch.Size([30, 12915])\n",
            "55: torch.Size([30, 8734])\n",
            "56: torch.Size([30, 208])\n",
            "57: torch.Size([30, 3072])\n",
            "58: torch.Size([30, 130])\n",
            "59: torch.Size([30, 446])\n",
            "60: torch.Size([30, 65])\n",
            "61: torch.Size([30, 2437])\n",
            "62: torch.Size([30, 25])\n",
            "63: torch.Size([30, 1358])\n",
            "64: torch.Size([30, 971])\n",
            "65: torch.Size([30, 1914])\n",
            "66: torch.Size([30, 933])\n",
            "67: torch.Size([30, 569])\n",
            "68: torch.Size([30, 656])\n",
            "69: torch.Size([30, 512])\n",
            "70: torch.Size([30, 2724])\n",
            "71: torch.Size([30, 952])\n",
            "72: torch.Size([30, 887])\n",
            "73: torch.Size([30, 704])\n",
            "74: torch.Size([30, 1353])\n",
            "75: torch.Size([30, 1248])\n",
            "76: torch.Size([30, 350])\n",
            "77: torch.Size([30, 1610])\n",
            "78: torch.Size([30, 1959])\n",
            "79: torch.Size([30, 3088])\n",
            "80: torch.Size([30, 1625])\n",
            "81: torch.Size([30, 232])\n",
            "82: torch.Size([30, 2037])\n",
            "83: torch.Size([30, 9450])\n",
            "84: torch.Size([30, 648])\n",
            "85: torch.Size([30, 2356])\n",
            "86: torch.Size([30, 2251])\n",
            "87: torch.Size([30, 1736])\n",
            "88: torch.Size([30, 1565])\n",
            "89: torch.Size([30, 3671])\n",
            "90: torch.Size([30, 3881])\n",
            "91: torch.Size([30, 536])\n",
            "92: torch.Size([30, 1875])\n",
            "93: torch.Size([30, 2225])\n",
            "94: torch.Size([30, 257])\n",
            "95: torch.Size([30, 3058])\n",
            "96: torch.Size([30, 731])\n",
            "97: torch.Size([30, 3088])\n",
            "98: torch.Size([30, 5250])\n",
            "99: torch.Size([30, 3230])\n",
            "100: torch.Size([30, 1669])\n",
            "101: torch.Size([30, 2395])\n",
            "102: torch.Size([30, 1078])\n",
            "103: torch.Size([30, 1057])\n",
            "104: torch.Size([30, 210])\n",
            "105: torch.Size([30, 4415])\n",
            "106: torch.Size([30, 1017])\n",
            "107: torch.Size([30, 3926])\n",
            "108: torch.Size([30, 1408])\n",
            "109: torch.Size([30, 1512])\n",
            "110: torch.Size([30, 4507])\n",
            "111: torch.Size([30, 773])\n",
            "112: torch.Size([30, 1891])\n",
            "113: torch.Size([30, 2704])\n",
            "114: torch.Size([30, 2230])\n",
            "115: torch.Size([30, 8108])\n",
            "116: torch.Size([30, 89])\n",
            "117: torch.Size([30, 3429])\n",
            "118: torch.Size([30, 2242])\n",
            "119: torch.Size([30, 318])\n",
            "120: torch.Size([30, 3103])\n",
            "121: torch.Size([30, 5590])\n",
            "122: torch.Size([30, 1539])\n",
            "123: torch.Size([30, 1012])\n",
            "124: torch.Size([30, 80])\n",
            "125: torch.Size([30, 276])\n",
            "126: torch.Size([30, 498])\n",
            "127: torch.Size([30, 1564])\n",
            "128: torch.Size([30, 3152])\n",
            "129: torch.Size([30, 3440])\n",
            "130: torch.Size([30, 1209])\n",
            "131: torch.Size([30, 399])\n",
            "132: torch.Size([30, 1914])\n",
            "133: torch.Size([30, 451])\n",
            "134: torch.Size([30, 687])\n",
            "135: torch.Size([30, 882])\n",
            "136: torch.Size([30, 1489])\n",
            "137: torch.Size([30, 1783])\n",
            "138: torch.Size([30, 976])\n",
            "139: torch.Size([30, 4170])\n",
            "140: torch.Size([30, 3023])\n",
            "141: torch.Size([30, 2767])\n",
            "142: torch.Size([30, 3631])\n",
            "143: torch.Size([30, 2029])\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-9ad3335c3ec9>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m outputs = model_eval_check(model, optimizer, test_dataloader, device, \n\u001b[0m\u001b[1;32m      4\u001b[0m                                                         get_embeddings = get_embeddings, silent = True)\n\u001b[1;32m      5\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-d267222db115>\u001b[0m in \u001b[0;36mmodel_eval_check\u001b[0;34m(model, optimizer, dataloader, device, get_embeddings, silent)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mspecies_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspecies_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecies_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_masked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/./ML4RG-2023-project/models/spec_dss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;31m# Apply S4 block: we ignore the state input and output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;31m# Dropout on the output of the S4 block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/./ML4RG-2023-project/models/dss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, u, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransposed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/./ML4RG-2023-project/models/dss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'... u l, v u -> ... v l'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/opt_einsum/contract.py\u001b[0m in \u001b[0;36mcontract\u001b[0;34m(*operands, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mContractExpression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstants_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meinsum_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_core_contract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meinsum_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/opt_einsum/contract.py\u001b[0m in \u001b[0;36m_core_contract\u001b[0;34m(operands, contraction_list, backend, evaluate_constants, **einsum_kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0;31m# Contract!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m             \u001b[0mnew_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtmp_operands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;31m# Build a new view if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/opt_einsum/sharing.py\u001b[0m in \u001b[0;36mcached_tensordot\u001b[0;34m(x, y, axes, backend)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcached_tensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'numpy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcurrently_sharing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# hash based on the (axes_x,axes_y) form of axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/opt_einsum/contract.py\u001b[0m in \u001b[0;36m_tensordot\u001b[0;34m(x, y, axes, backend)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \"\"\"\n\u001b[1;32m    373\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tensordot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/opt_einsum/backends/torch.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(x, y, axes)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_TORCH_HAS_TENSORDOT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mxnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(a, b, dims, out)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims_b\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import time\n",
        "start = time.time()\n",
        "outputs = model_eval_check(model, optimizer, test_dataloader, device,\n",
        "                                                        get_embeddings = get_embeddings, silent = True)\n",
        "end = time.time()\n",
        "print(\"Time taken in mins: \", (end-start)/60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "X4b0dGoG1M8g"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "outputs_file = \"outputs.pickle\"\n",
        "with open(outputs_file, \"wb\") as f:\n",
        "    pickle.dump(outputs, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCp_1J1HHXIZ",
        "outputId": "9b008325-e5ce-4a43-dc3a-600fc1a5cae4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "species_encoder = SpecAdd(embed = True, encoder = 'label', d_model = d_model)\n",
        "\n",
        "model = DSSResNetEmb(d_input = 5, d_output = 5, d_model = d_model, n_layers = n_layers, dropout = dropout, embed_before = True, species_encoder = species_encoder)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "model_params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "optimizer = torch.optim.Adam(model_params, lr = learn_rate, weight_decay = weight_decay)\n",
        "\n",
        "last_epoch = 0\n",
        "model_weight = \"MLM_mammals_species_aware_5000_weights\"\n",
        "model.load_state_dict(torch.load(model_weight))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHOVe0-BHb2j",
        "outputId": "33860611-c991-4aa3-b3b6-31a5bb643725"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023/07/02-08:23:40]- Test/Inference...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/./ML4RG-2023-project/helpers/train_eval.py:100: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  species_label = torch.tensor(species_label).long().to(device)\n",
            "/content/./ML4RG-2023-project/models/dss.py:335: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at ../aten/src/ATen/native/Copy.cpp:276.)\n",
            "  return einsum('chn,hnl->chl', W, S).float(), state                   # [C H L]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1338: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.\n",
            "  warnings.warn(\"dropout2d: Received a 3D input to dropout2d and assuming that channel-wise \"\n"
          ]
        }
      ],
      "source": [
        "predictions_dir = os.path.join(output_dir, 'predictions') #dir to save predictions\n",
        "weights_dir = os.path.join(output_dir, 'weights') #dir to save model weights at save_at epochs\n",
        "if save_at:\n",
        "    os.makedirs(weights_dir, exist_ok = True)\n",
        "\n",
        "def metrics_to_str(metrics):\n",
        "    loss, total_acc, masked_acc = metrics\n",
        "    return f'loss: {loss:.4}, total acc: {total_acc:.3f}, masked acc: {masked_acc:.3f}'\n",
        "\n",
        "from helpers.misc import print    #print function that displays time\n",
        "print(f'Test/Inference...')\n",
        "\n",
        "test_metrics, test_embeddings =  train_eval.model_eval(model, optimizer, test_dataloader, device,\n",
        "                                                          get_embeddings = get_embeddings, silent = True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yvk3vrQBIoiX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
