{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a423d44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0, '../../')\n",
    "\n",
    "import gc\n",
    "import pysam\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import openpyxl\n",
    "\n",
    "\n",
    "import helpers.train_eval as train_eval    #train and evaluation\n",
    "import helpers.misc as misc                #miscellaneous functions\n",
    "from helpers.plots import MetricsHandler, MotifMetrics\n",
    "from helpers.motifs import motifs\n",
    "\n",
    "import encoding_utils.sequence_encoders as sequence_encoders\n",
    "import encoding_utils.sequence_utils as sequence_utils\n",
    "from models.spec_dss import DSSResNet, DSSResNetEmb, SpecAdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96eb7626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A1CF', 'AATTA', 0), ('BOLL', 'TTTTT', 1), ('CELF1', 'TATGT', 2), ('CNOT4', 'ACACA', 3), ('DAZ3', 'AGTTA', 4), ('DAZAP1', 'ATATA', 5), ('EIF4G2', 'GTTGC', 6), ('ESRP1', 'GGGGG', 7), ('FUBP3', 'TATAT', 8), ('HNRNPA0', 'TATAG', 9), ('HNRNPD', 'TATTA', 10), ('HNRNPDL', 'TAATT', 11), ('HNRNPK', 'GCCCA', 12), ('KHDRBS2', 'ATAAA', 13), ('KHSRP', 'TGTAT', 14), ('MBNL1', 'CGCTT', 15), ('MSI1', 'TAGTT', 16), ('NOVA1', 'TTCAT', 17), ('NUPL2', 'AAAAA', 18), ('PCBP1', 'GCCCC', 19), ('PCBP2', 'CCCCC', 20), ('PCBP4', 'ATCCC', 21), ('PRR3', 'ATAAG', 22), ('PTBP3', 'TTTCT', 23), ('RBFOX2', 'GCATG', 24), ('RBM22', 'ACCGG', 25), ('RBM24', 'GTGTG', 26), ('RBM4', 'GCGCG', 27), ('RBM41', 'TACTT', 28), ('RBM45', 'ACGCA', 29), ('RBM47', 'AATCA', 30), ('RBM6', 'CGTCC', 31), ('RC3H1', 'ATATT', 32), ('SF1', 'TAACA', 33), ('SFPQ', 'TGTAA', 34), ('SNRPA', 'TGCAC', 35), ('SRSF10', 'AGCAG', 36), ('SRSF11', 'AGGGG', 37), ('SRSF8', 'GCAGC', 38), ('SRSF9', 'AGGAG', 39), ('TARDBP', 'GTATG', 40), ('TRA2A', 'GAAGA', 41), ('UNK', 'TTAGT', 42), ('ZCRB1', 'TTAAT', 43), ('ZFP36', 'TATTT', 44), ('ZNF326', 'GGATG', 45), ('BOLL', 'TGTTT', 46), ('CELF1', 'TTTGT', 47), ('CNOT4', 'ACAGA', 48), ('CPEB1', 'TTTTA', 49), ('DAZ3', 'AGTTT', 50), ('EIF4G2', 'GCGAG', 51), ('ELAVL4', 'TTATT', 52), ('ESRP1', 'GGTGG', 53), ('HNRNPA0', 'ATTAG', 54), ('HNRNPC', 'ATTTT', 55), ('HNRNPDL', 'TAATA', 56), ('HNRNPK', 'CACGC', 57), ('HNRNPL', 'ACATA', 58), ('IGF2BP1', 'ATACA', 59), ('IGF2BP2', 'CAACA', 60), ('KHDRBS2', 'TTAAA', 61), ('MBNL1', 'GCTGC', 62), ('MSI1', 'TAGTA', 63), ('NOVA1', 'ATCAT', 64), ('NUPL2', 'AAAAG', 65), ('PABPN1L', 'AAAAT', 66), ('PCBP2', 'CCCCA', 67), ('PCBP4', 'TTCCC', 68), ('PTBP3', 'TCTTT', 69), ('RALY', 'TTCTT', 70), ('RBFOX2', 'GCACG', 71), ('RBM22', 'TCCGG', 72), ('RBM23', 'CCTCC', 73), ('RBM24', 'GTGTT', 74), ('RBM25', 'GGGGC', 75), ('RBM4', 'GCGCA', 76), ('RBM41', 'TACAT', 77), ('RBM45', 'ACGAC', 78), ('RBM4B', 'CGCGG', 79), ('RBM6', 'GTCCC', 80), ('RC3H1', 'TTATA', 81), ('SF1', 'TAACC', 82), ('SFPQ', 'GTAAG', 83), ('SNRPA', 'GCACA', 84), ('SRSF8', 'GCAGT', 85), ('SRSF9', 'AGGAA', 86), ('TRA2A', 'AAGAA', 87), ('ZCRB1', 'ATTAA', 88), ('ZNF326', 'GATCG', 89), ('CELF1', 'TGTGT', 90), ('DAZ3', 'GTTTT', 91), ('DAZAP1', 'TATAA', 92), ('EIF4G2', 'CGCCG', 93), ('ESRP1', 'GGGGT', 94), ('EWSR1', 'GGGTG', 95), ('FUBP3', 'TTTAT', 96), ('HNRNPA0', 'TTTAG', 97), ('HNRNPA2B1', 'GGGTA', 98), ('HNRNPC', 'CTTTT', 99), ('HNRNPDL', 'TAAAT', 100), ('HNRNPF', 'TGGGG', 101), ('IGF2BP1', 'CATCA', 102), ('KHDRBS2', 'CTAAA', 103), ('KHDRBS3', 'TAAAA', 104), ('MBNL1', 'CGCGC', 105), ('NOVA1', 'CATAA', 106), ('PCBP1', 'AGCCC', 107), ('PCBP2', 'TCCCC', 108), ('PRR3', 'ATGAG', 109), ('PTBP3', 'CTATC', 110), ('PUF60', 'TCTCT', 111), ('PUM1', 'TGTAC', 112), ('RBM22', 'TACCG', 113), ('RBM4', 'GCGTA', 114), ('RBM41', 'TACGT', 115), ('RBM47', 'ATAAT', 116), ('RBM4B', 'GCGGG', 117), ('RBM6', 'TCCAC', 118), ('SFPQ', 'TAGTG', 119), ('SNRPA', 'AGCAC', 120), ('SRSF10', 'CAGCA', 121), ('SRSF11', 'AGGGA', 122), ('SRSF2', 'TGCAG', 123), ('SRSF5', 'GCGCC', 124), ('TARDBP', 'GAATG', 125), ('TRA2A', 'GAAAA', 126), ('TRNAU1AP', 'ATTTA', 127), ('UNK', 'TAGGT', 128), ('ZCRB1', 'TTTAA', 129), ('ZNF326', 'CGGAC', 130), ('A1CF', 'AATAA', 131), ('BOLL', 'TGTTA', 132), ('CELF1', 'TGTCT', 133), ('CNOT4', 'ACAGT', 134), ('DAZ3', 'ATGTT', 135), ('DAZAP1', 'ATAGT', 136), ('EIF4G2', 'GGTCG', 137), ('EWSR1', 'AGGTG', 138), ('FUBP3', 'ATTAT', 139), ('HNRNPA0', 'AATAG', 140), ('HNRNPF', 'GGGAG', 141), ('HNRNPL', 'CACAT', 142), ('MBNL1', 'TGCTT', 143), ('NOVA1', 'CATAC', 144), ('PCBP1', 'CCCCG', 145), ('PCBP2', 'CCCCT', 146), ('PCBP4', 'ATCCT', 147), ('RBM4', 'GCGTG', 148), ('RBM45', 'TACGC', 149), ('RBM47', 'AAATT', 150), ('RBM4B', 'GCGGT', 151), ('SFPQ', 'GTAAT', 152), ('SNRPA', 'CGCAC', 153), ('SRSF11', 'AGAGG', 154), ('SRSF2', 'TCCAG', 155), ('SRSF9', 'TGGAG', 156), ('TARDBP', 'GAGTG', 157), ('TRA2A', 'GAAGC', 158), ('ZCRB1', 'CTTAA', 159), ('ZNF326', 'ATTCC', 160), ('A1CF', 'AATGA', 161), ('CNOT4', 'CACAG', 162), ('DAZ3', 'GTTTA', 163), ('HNRNPF', 'AGGGT', 164), ('HNRNPH2', 'GTGGG', 165), ('HNRNPL', 'TACAC', 166), ('MSI1', 'ATAGA', 167), ('NOVA1', 'CTCAT', 168), ('PCBP2', 'ACCCC', 169), ('PTBP3', 'CTTCT', 170), ('RBM4', 'CGCGT', 171), ('RBM45', 'GACGC', 172), ('RBM4B', 'CGGGG', 173), ('RBM6', 'ATCCA', 174), ('RBMS2', 'TATAC', 175), ('SF1', 'TTAAC', 176), ('SFPQ', 'AGTAA', 177), ('SNRPA', 'CACAC', 178), ('SRSF9', 'GGGAA', 179), ('TRA2A', 'GAATA', 180), ('ZNF326', 'GGACG', 181), ('A1CF', 'CTAAT', 182), ('BOLL', 'TTTTC', 183), ('CNOT4', 'ACAGC', 184), ('HNRNPA0', 'CTAGG', 185), ('HNRNPF', 'TGGGT', 186), ('HNRNPH2', 'GGGGA', 187), ('HNRNPL', 'ACATT', 188), ('MBNL1', 'CGCTA', 189), ('NOVA1', 'CATTA', 190), ('PCBP1', 'CGCCC', 191), ('PTBP3', 'TCTAT', 192), ('RBM24', 'GTTTG', 193), ('RBM4', 'GCGCT', 194), ('RBM45', 'ACGAA', 195), ('RBM47', 'AATCT', 196), ('RBM6', 'CCACC', 197), ('RBMS2', 'CTATA', 198), ('SNRPA', 'TTCAC', 199), ('TRA2A', 'CCGAA', 200), ('ZNF326', 'GGGAC', 201), ('BOLL', 'TTGTT', 202), ('CELF1', 'TGTCC', 203), ('HNRNPA0', 'CTTAG', 204), ('MBNL1', 'AGCTT', 205), ('NUPL2', 'CAAAA', 206), ('PCBP1', 'TGCCC', 207), ('PRR3', 'ATTAC', 208), ('PTBP3', 'CTTTC', 209), ('RBM4', 'TGCGT', 210), ('RBM45', 'CTTAC', 211), ('RBM4B', 'ACGGG', 212), ('RBMS2', 'GTATA', 213), ('SF1', 'ATAAC', 214), ('SRSF8', 'GCCGC', 215), ('TRA2A', 'CTGAA', 216), ('UNK', 'TTAGC', 217), ('HNRNPA0', 'ATAGG', 218), ('KHDRBS2', 'TAAAC', 219), ('MSI1', 'AGTAG', 220), ('NOVA1', 'CATTT', 221), ('NUPL2', 'AAAAC', 222), ('PCBP4', 'TTCCT', 223), ('PRR3', 'ATGAA', 224), ('RBM45', 'ACTAC', 225), ('RBM47', 'TGATT', 226), ('RBM4B', 'TCGGG', 227), ('RC3H1', 'CTATG', 228), ('CELF1', 'AATGT', 229), ('DAZ3', 'CAGTT', 230), ('HNRNPA0', 'TTAGG', 231), ('MBNL1', 'TGCTA', 232), ('MSI1', 'TTAGA', 233), ('NOVA1', 'CATAT', 234), ('NUPL2', 'AAAGG', 235), ('PCBP2', 'TACCC', 236), ('PCBP4', 'GTCGG', 237), ('RBM45', 'ACGCC', 238), ('RBM4B', 'ACGCG', 239), ('SF1', 'TAATC', 240), ('TRA2A', 'CAGAA', 241), ('TRNAU1AP', 'AATTT', 242), ('UNK', 'TAGCA', 243), ('DAZ3', 'GTTAT', 244), ('MSI1', 'TAGAT', 245), ('NOVA1', 'TCACA', 246), ('NUPL2', 'AAATG', 247), ('RBM45', 'CTGAC', 248), ('RBM4B', 'CGGTA', 249), ('SF1', 'CTAAC', 250), ('TRA2A', 'AGAAA', 251), ('BOLL', 'TTTTG', 252), ('DAZ3', 'CGTTT', 253), ('HNRNPA0', 'GTTAG', 254), ('KHDRBS2', 'ACTAA', 255), ('NOVA1', 'CCATA', 256), ('NUPL2', 'CAAAG', 257), ('PCBP2', 'CCCTC', 258), ('RBM45', 'ACGCT', 259), ('SF1', 'TAACT', 260), ('DAZ3', 'AAGTT', 261), ('MSI1', 'TAGCT', 262), ('NUPL2', 'AAATA', 263), ('PCBP2', 'AACCC', 264), ('DAZ3', 'CGTTA', 265), ('NOVA1', 'CATTC', 266), ('PCBP1', 'CCGCC', 267), ('PCBP2', 'CCCAC', 268), ('RBM45', 'ACACC', 269), ('MSI1', 'TAGAA', 270), ('NOVA1', 'CCATC', 271), ('UNK', 'ACTAG', 272), ('NOVA1', 'TCATA', 273), ('UNK', 'CATAG', 274), ('DAZ3', 'ACGTT', 275), ('NOVA1', 'ATCAC', 276)]\n",
      "78\n",
      "277\n"
     ]
    }
   ],
   "source": [
    "### Finding all the \n",
    "\n",
    "xlsx_file_path = \"../../../dataset/1-s2.0-S1097276518303514-mmc4.xlsx\"\n",
    "\n",
    "\n",
    "\n",
    "def find_index(element, my_list):\n",
    "    return next((index for index, value in enumerate(my_list) if value == element), -1)\n",
    "\n",
    "\n",
    "# Load the XLSX file\n",
    "workbook = openpyxl.load_workbook(xlsx_file_path)\n",
    "sheet = workbook['logo_5mers.prop_in_logo']  # Replace \"Sheet1\" with the actual sheet name\n",
    "data = []\n",
    "for row in sheet.iter_rows(values_only=True):\n",
    "    data.append(row)\n",
    "\n",
    "strong_motifs = []\n",
    "seq_only = []\n",
    "motif_tup = []\n",
    "r1_val = []\n",
    "protein_name = []\n",
    "iteri =0 \n",
    "# Print the data\n",
    "\n",
    "for i,row in enumerate(data):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    if i == 1:\n",
    "        for j in range(0,int(len(row)/2)):\n",
    "            protein_name.append(row[(j*2)])\n",
    "    if i > 1:        \n",
    "        for j in range(0,int(len(row)/2)):\n",
    "            mot = row[(j*2)]\n",
    "            r1 = row[(j*2)+1]\n",
    "            if mot not in strong_motifs and mot!=None:\n",
    "                strong_motifs.append(mot)\n",
    "                seq_only.append(mot)\n",
    "                motif_tup.append((protein_name[j],mot,iteri))\n",
    "                iteri +=1\n",
    "                r1_val.append(r1)\n",
    "            elif mot in strong_motifs: \n",
    "                ind = find_index(mot,strong_motifs)\n",
    "                if r1_val[ind] < r1 :\n",
    "                    r1_val[ind] = r1\n",
    "\n",
    "\n",
    "print (motif_tup)\n",
    "print (len(protein_name))\n",
    "print (len(strong_motifs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a40ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.motifs import MotifHandler\n",
    "\n",
    "new_motifs = MotifHandler(motif_tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5fd51ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, fasta_fa, seq_df, transform, motifs):\n",
    "        \n",
    "        self.fasta = pysam.FastaFile(fasta_fa)\n",
    "        \n",
    "        self.val_fraction = 0.1 \n",
    "        N_train = int(len(seq_df) * (1-self.val_fraction))\n",
    "        self.start_index = N_train \n",
    "        self.seq_df = seq_df\n",
    "        self.transform = transform\n",
    "\n",
    "        self.motifs = motifs\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.seq_df[self.start_index:])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        seq = self.fasta.fetch(self.seq_df.iloc[self.start_index + idx].seq_name).upper()\n",
    "        #print(seq)\n",
    "                \n",
    "        species_label = self.seq_df.iloc[self.start_index + idx].species_label\n",
    "        #print(species_label)\n",
    "        # x_batch, y_masked_batch, y_batch, mask_batch, motif_mask_batch \n",
    "        masked_sequence, target_labels_masked, target_labels, mask, motif_mask_batch = self.transform(seq, motifs = self.motifs)\n",
    "        \n",
    "        masked_sequence = (masked_sequence, species_label)\n",
    "        return masked_sequence, target_labels_masked, target_labels, motif_mask_batch\n",
    "    \n",
    "    def close(self):\n",
    "        self.fasta.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b43ba93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_name</th>\n",
       "      <th>species_name</th>\n",
       "      <th>species_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000641515.2_utr3_2_0_chr1_70009_f:Homo_s...</td>\n",
       "      <td>Homo_sapiens</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000616016.5_utr3_13_0_chr1_944154_f:Homo...</td>\n",
       "      <td>Homo_sapiens</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000327044.7_utr3_18_0_chr1_944203_r:Homo...</td>\n",
       "      <td>Homo_sapiens</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000338591.8_utr3_11_0_chr1_965192_f:Homo...</td>\n",
       "      <td>Homo_sapiens</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000379410.8_utr3_15_0_chr1_974576_f:Homo...</td>\n",
       "      <td>Homo_sapiens</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18129</th>\n",
       "      <td>ENST00000303766.12_utr3_11_0_chrY_22168542_r:H...</td>\n",
       "      <td>Homo_sapiens</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18130</th>\n",
       "      <td>ENST00000250831.6_utr3_11_0_chrY_22417604_f:Ho...</td>\n",
       "      <td>Homo_sapiens</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18131</th>\n",
       "      <td>ENST00000303728.5_utr3_4_0_chrY_22514071_f:Hom...</td>\n",
       "      <td>Homo_sapiens</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18132</th>\n",
       "      <td>ENST00000382407.1_utr3_0_0_chrY_24045793_r:Hom...</td>\n",
       "      <td>Homo_sapiens</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18133</th>\n",
       "      <td>ENST00000306609.5_utr3_1_0_chrY_25624528_f:Hom...</td>\n",
       "      <td>Homo_sapiens</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18134 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                seq_name  species_name  \\\n",
       "0      ENST00000641515.2_utr3_2_0_chr1_70009_f:Homo_s...  Homo_sapiens   \n",
       "1      ENST00000616016.5_utr3_13_0_chr1_944154_f:Homo...  Homo_sapiens   \n",
       "2      ENST00000327044.7_utr3_18_0_chr1_944203_r:Homo...  Homo_sapiens   \n",
       "3      ENST00000338591.8_utr3_11_0_chr1_965192_f:Homo...  Homo_sapiens   \n",
       "4      ENST00000379410.8_utr3_15_0_chr1_974576_f:Homo...  Homo_sapiens   \n",
       "...                                                  ...           ...   \n",
       "18129  ENST00000303766.12_utr3_11_0_chrY_22168542_r:H...  Homo_sapiens   \n",
       "18130  ENST00000250831.6_utr3_11_0_chrY_22417604_f:Ho...  Homo_sapiens   \n",
       "18131  ENST00000303728.5_utr3_4_0_chrY_22514071_f:Hom...  Homo_sapiens   \n",
       "18132  ENST00000382407.1_utr3_0_0_chrY_24045793_r:Hom...  Homo_sapiens   \n",
       "18133  ENST00000306609.5_utr3_1_0_chrY_25624528_f:Hom...  Homo_sapiens   \n",
       "\n",
       "       species_label  \n",
       "0                181  \n",
       "1                181  \n",
       "2                181  \n",
       "3                181  \n",
       "4                181  \n",
       "...              ...  \n",
       "18129            181  \n",
       "18130            181  \n",
       "18131            181  \n",
       "18132            181  \n",
       "18133            181  \n",
       "\n",
       "[18134 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasta_fa = \"../../../dataset/data_homo/Homo_sapiens_3prime_UTR.fa\"\n",
    "species_list = \"../../240_species.txt\"\n",
    "species_agnostic = False\n",
    "\n",
    "seq_df = pd.read_csv(fasta_fa + '.fai', header=None, sep='\\t', usecols=[0], names=['seq_name'])\n",
    "seq_df['species_name'] = seq_df.seq_name.apply(lambda x:x.split(':')[1])\n",
    "species_encoding = pd.read_csv(species_list, header=None).squeeze().to_dict()\n",
    "\n",
    "if not species_agnostic:\n",
    "    species_encoding = {species:idx for idx,species in species_encoding.items()}\n",
    "else:\n",
    "    species_encoding = {species:0 for _,species in species_encoding.items()}\n",
    "\n",
    "species_encoding['Homo_sapiens'] = species_encoding['Pan_troglodytes']\n",
    "seq_df['species_label'] = seq_df.species_name.map(species_encoding)\n",
    "\n",
    "seq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "96565dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1814"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kseq_len = 5000\n",
    "total_len = 5000\n",
    "\n",
    "seq_transform = sequence_encoders.RollingMasker()      \n",
    "test_dataset = SeqDataset(fasta_fa, seq_df, transform = seq_transform, motifs=new_motifs.dict)\n",
    "test_dataloader = DataLoader(dataset = test_dataset, batch_size = 1, num_workers = 1, collate_fn = None, shuffle = False)\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "27bfda94",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# test wether cuda is available - if cpu_bool is set to True, cuda is not used\n",
    "\n",
    "# TODO checkout why gpu isn't working\n",
    "cpu_bool = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not cpu_bool else \"cpu\")\n",
    "\n",
    "d_model = 128\n",
    "n_layers = 4\n",
    "dropout = 0.\n",
    "learn_rate = 1e-4\n",
    "weight_decay = 0.\n",
    "output_dir = \"./test/\"\n",
    "get_embeddings = True\n",
    "save_at = None\n",
    "\n",
    "species_encoder = SpecAdd(embed = True, encoder = 'label', d_model = 128)\n",
    "\n",
    "model = DSSResNetEmb(d_input = 5, d_output = 5, d_model = d_model, n_layers = n_layers, \n",
    "                     dropout = dropout, embed_before = True, species_encoder = species_encoder)\n",
    "\n",
    "model = model.to(device) \n",
    "\n",
    "model_params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = torch.optim.Adam(model_params, lr = learn_rate, weight_decay = weight_decay)\n",
    "\n",
    "last_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16487581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not species_agnostic:\n",
    "    model_weight = \"../../../dataset/data_homo/MLM_mammals_species_aware_5000_weights\"\n",
    "else :\n",
    "    model_weight = \"../../../dataset/data_homo/MLM_mammals_species_agnostic_5000_weights\"\n",
    "# load model but avoid torch._C._cuda_getDeviceCount() > 0 failed error\n",
    "model.load_state_dict(torch.load(model_weight, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8a2957d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions_dir = os.path.join(output_dir, 'predictions') #dir to save predictions\n",
    "weights_dir = os.path.join(output_dir, 'weights') #dir to save model weights at save_at epochs\n",
    "if save_at:\n",
    "    os.makedirs(weights_dir, exist_ok = True)\n",
    "\n",
    "def metrics_to_str(metrics):\n",
    "    loss, total_acc, masked_acc = metrics\n",
    "    return f'loss: {loss:.4}, total acc: {total_acc:.3f}, masked acc: {masked_acc:.3f}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4eee4ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from helpers.metrics import MaskedAccuracy\n",
    "def model_eval_check(model, optimizer, dataloader, device, get_embeddings = False, silent=False):\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction = \"mean\")\n",
    "\n",
    "    metric = MaskedAccuracy()\n",
    "    motif_metric = MaskedAccuracy()\n",
    "\n",
    "    model.eval() #model to train mode\n",
    "\n",
    "    if not silent:\n",
    "        tot_itr = len(dataloader.dataset)//dataloader.batch_size #total train iterations\n",
    "        pbar = tqdm(total = tot_itr, ncols=700) #progress bar\n",
    "\n",
    "    avg_loss, masked_acc, total_acc = 0., 0., 0.\n",
    "    \n",
    "    all_embeddings = []\n",
    "    outputs = []\n",
    "    with torch.no_grad():\n",
    "        #               x_batch, y_masked_batch, y_batch, mask_batch, motif_mask_batch\n",
    "        for itr_idx, (((masked_sequence, species_label), targets_masked, targets, motif_mask)) in enumerate(dataloader):\n",
    "            \n",
    "            if get_embeddings:\n",
    "                #batches are generated by transformation in the dataset,\n",
    "                #so remove extra batch dimension added by dataloader\n",
    "                masked_sequence, targets_masked, targets = masked_sequence[0], targets_masked[0], targets[0]\n",
    "                species_label = species_label.tile((len(masked_sequence),))\n",
    "            \n",
    "            masked_sequence = masked_sequence.to(device)\n",
    "            targets_masked = targets_masked.to(device)\n",
    "\n",
    "            motif_targets=targets.detach().clone()\n",
    "            motif_targets[motif_mask.squeeze()== 0] = -100.0\n",
    "            print(f\"{itr_idx}: {motif_targets.shape}\")\n",
    "            motif_targets[targets_masked == -100] = -100.0\n",
    "            targets = targets.to(device)\n",
    "            species_label = torch.tensor(species_label).long().to(device)\n",
    "            \n",
    "            logits, embeddings = model(masked_sequence, species_label)\n",
    "\n",
    "            loss = criterion(logits, targets_masked)\n",
    "\n",
    "            avg_loss += loss.item()\n",
    "                \n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "\n",
    "            test_acc_motif = motif_metric(preds, motif_targets)\n",
    "            masked_acc += metric(preds, targets_masked).detach() # compute only on masked nucleotides\n",
    "            total_acc += metric(preds, targets).detach()\n",
    "            #print(masked_acc/(itr_idx+1))\n",
    "                \n",
    "            if get_embeddings:\n",
    "                # only get embeddings of the masked nucleotide\n",
    "                sequence_embedding = embeddings[\"seq_embedding\"]\n",
    "                sequence_embedding = sequence_embedding.transpose(-1,-2)[targets_masked!=-100]\n",
    "                # shape # B, L, dim  to L,dim, left with only masked nucleotide embeddings\n",
    "                # average over sequence \n",
    "                #print(sequence_embedding.shape)\n",
    "                sequence_embedding = sequence_embedding.mean(dim=0) # if we mask\n",
    "                #sequence_embedding = sequence_embedding[0].mean(dim=-1) # no mask\n",
    "\n",
    "                sequence_embedding = sequence_embedding.detach().cpu().numpy()\n",
    "                all_embeddings.append(sequence_embedding)\n",
    "                \n",
    "            if not silent:\n",
    "                pbar.update(1)\n",
    "                pbar.set_description(f\"acc: {total_acc/(itr_idx+1):.2}, masked acc: {masked_acc/(itr_idx+1):.2}, motif acc {test_acc_motif/(itr_idx+1):.2} loss: {avg_loss/(itr_idx+1):.4}\")\n",
    "            outputs.append({\"loss\": loss, \"preds\": preds, \"logits\": logits, \"targets\": targets_masked, \"motifs\": motif_mask})\n",
    "    if not silent:\n",
    "        del pbar\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2865d290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: torch.Size([30, 4956])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_154386/3636492396.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  species_label = torch.tensor(species_label).long().to(device)\n",
      "/home/anas/anaconda3/envs/ML4RG-mlm/lib/python3.9/site-packages/torch/nn/functional.py:1338: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.\n",
      "  warnings.warn(\"dropout2d: Received a 3D input to dropout2d and assuming that channel-wise \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: torch.Size([30, 1214])\n",
      "2: torch.Size([30, 892])\n",
      "3: torch.Size([30, 511])\n",
      "4: torch.Size([30, 504])\n",
      "5: torch.Size([30, 555])\n",
      "6: torch.Size([30, 2448])\n",
      "7: torch.Size([30, 2522])\n",
      "8: torch.Size([30, 6014])\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "outputs = model_eval_check(model, optimizer, test_dataloader, device, \n",
    "                                                        get_embeddings = get_embeddings, silent = True)\n",
    "end = time.time()\n",
    "print(\"Time taken in mins: \", (end-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "527dfd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "outputs_file = \"../../../our_code/results/species_aware/outputs.pickle\"\n",
    "with open(outputs_file, \"wb\") as f:\n",
    "    pickle.dump(outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49062558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No nan entries in preds\n"
     ]
    }
   ],
   "source": [
    "motif_metrics = MotifMetrics(outputs=outputs, plots_dir=\"../../../our_code/results/species_aware/\", motif_dict=new_motifs.dict, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea069bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.set_theme(context=\"poster\")\n",
    "sns.set_theme()\n",
    "#sns.set_context(\"talk\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "sns.set_context(\"talk\", font_scale=1.7)#, rc={\"font.size\": 7})\n",
    "#\n",
    "#sns.set_context(\"poster\", \n",
    "sns.set_style(style={'xtick.bottom': True,'ytick.left': True, 'axes.edgecolor': 'black'})\n",
    "#sns.set_style(\"ticks\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
