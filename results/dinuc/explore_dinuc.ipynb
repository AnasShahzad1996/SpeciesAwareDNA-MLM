{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9xlU-UNDF1nu"
      },
      "source": [
        "# Notebook ML4RG-Project\n",
        "\n",
        "First download the data and install the needed packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yaxJnR293QS",
        "outputId": "45e630fc-5487-4db0-a725-32d20509e287"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ML4RG-2023-project'...\n",
            "remote: Enumerating objects: 248, done.\u001b[K\n",
            "remote: Counting objects: 100% (248/248), done.\u001b[K\n",
            "remote: Compressing objects: 100% (208/208), done.\u001b[K\n",
            "remote: Total 248 (delta 113), reused 134 (delta 30), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (248/248), 2.98 MiB | 17.41 MiB/s, done.\n",
            "Resolving deltas: 100% (113/113), done.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16BUHUYXNYvndfsiECB8-C7cwWq82oTg-\n",
            "To: /content/ML4RG-2023-project.tar\n",
            "100% 39.8M/39.8M [00:00<00:00, 96.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "![[ ! -d ML4RG-2023-project ]] && git clone https://github.com/Hugenotte585/ML4RG-2023-project.git\n",
        "!gdown https://drive.google.com/uc?id=16BUHUYXNYvndfsiECB8-C7cwWq82oTg-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuNw_UyuFKxm",
        "outputId": "363b1cd3-2676-4cd6-9eab-806b386299e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Homo_sapiens_3prime_UTR.fa\n",
            "Homo_sapiens_3prime_UTR.fa.fai\n",
            "MLM_mammals_species_aware_5000_weights\n"
          ]
        }
      ],
      "source": [
        "!tar -xvf ML4RG-2023-project.tar\n",
        "!rm ML4RG-2023-project.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfS38pRC-HV7",
        "outputId": "6e86ae89-2e80-4605-b2c2-d39004c28d15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting biopython\n",
            "  Downloading biopython-1.81-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.22.4)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.81\n"
          ]
        }
      ],
      "source": [
        "!pip -q install pysam\n",
        "!pip -q install torchmetrics\n",
        "!pip -q install einops\n",
        "!pip -q install omegaconf\n",
        "!pip install biopython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1TK2pn7T85z5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import sys, os\n",
        "#sys.path.insert(0, './ML4RG-2023-project')\n",
        "sys.path.insert(0, '../..')\n",
        "\n",
        "import gc\n",
        "import pysam\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import helpers.train_eval as train_eval    #train and evaluation\n",
        "import helpers.misc as misc                #miscellaneous functions\n",
        "\n",
        "import encoding_utils.sequence_encoders as sequence_encoders\n",
        "import encoding_utils.sequence_utils as sequence_utils\n",
        "from models.spec_dss import DSSResNet, DSSResNetEmb, SpecAdd\n",
        "from models.baseline.markov_model import *\n",
        "from models.baseline.markov_for_dinuc import *\n",
        "from Bio import SeqIO\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7wJoXm4JxIP8"
      },
      "outputs": [],
      "source": [
        "dinucl = [\"AA\", \"AC\", \"AT\", \"AG\", \"CA\", \"CC\", \"CT\", \"CG\", \"TA\", \"TC\", \"TT\", \"TG\", \"GA\", \"GC\", \"GG\", \"GT\"]\n",
        "count_dinuc = dict((el, 0) for el in dinucl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYIVJA2BxQKo",
        "outputId": "f5aa5281-65eb-4e6b-b6a0-ebbe9a34e87b"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(record\u001b[39m.\u001b[39mseq)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m      5\u001b[0m     pair\u001b[39m=\u001b[39mrecord\u001b[39m.\u001b[39mseq[i:i\u001b[39m+\u001b[39m\u001b[39m2\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m     \u001b[39mif\u001b[39;00m pair \u001b[39m==\u001b[39;49m nucleotide:\n\u001b[1;32m      7\u001b[0m         count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      8\u001b[0m count_dinuc[nucleotide] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m count\n",
            "File \u001b[0;32m~/.local/lib/anaconda3/envs/ML4RG-mlm/lib/python3.9/site-packages/Bio/Seq.py:419\u001b[0m, in \u001b[0;36m_SeqAbstractBaseClass.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__eq__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m    385\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compare the sequence to another sequence or a string.\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \n\u001b[1;32m    387\u001b[0m \u001b[39m    Sequences are equal to each other if their sequence contents is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[39m    True\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, _SeqAbstractBaseClass):\n\u001b[1;32m    420\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data \u001b[39m==\u001b[39m other\u001b[39m.\u001b[39m_data\n\u001b[1;32m    421\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, \u001b[39mstr\u001b[39m):\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for record in SeqIO.parse('../../../test/Homo_sapiens_3prime_UTR.fa', 'fasta'):\n",
        "    for nucleotide in count_dinuc:\n",
        "        count = 0\n",
        "        for i in range(len(record.seq)-1):\n",
        "            pair=record.seq[i:i+2]\n",
        "            if pair == nucleotide:\n",
        "                count += 1\n",
        "        count_dinuc[nucleotide] += count\n",
        "print('\\n'.join(['{}: {}'.format(i,count_dinuc[i]) for i in count_dinuc]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vvq2OU4YxytZ"
      },
      "outputs": [],
      "source": [
        "s_di = sum(count_dinuc.values())\n",
        "a2 = {k: v / 4989147 for k, v in count_dinuc.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QdBZIsYx-pH",
        "outputId": "a2dee9a2-95d6-453e-beb3-1300046f5870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A: 5919083\n",
            "C: 4863209\n",
            "T: 6414380\n",
            "G: 4935864\n"
          ]
        }
      ],
      "source": [
        "count_nucletides = dict([(i,0) for i in \"ACTG\"])\n",
        "for record in SeqIO.parse('../../../test/Homo_sapiens_3prime_UTR.fa', 'fasta'):\n",
        "    for nucleotide in count_nucletides:\n",
        "        count_nucletides[nucleotide] += record.seq.count(nucleotide)\n",
        "print('\\n'.join(['{}: {}'.format(i,count_nucletides[i]) for i in count_nucletides]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uogBjagwyAel"
      },
      "outputs": [],
      "source": [
        "s = sum(count_nucletides.values())\n",
        "a = {k: v / s for k, v in count_nucletides.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jdwyCvp1mgK",
        "outputId": "a21f13aa-0748-4eee-8a27-1d4534002f3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'A': 0.26743808301046024,\n",
              " 'C': 0.21973121381119634,\n",
              " 'T': 0.2898167656883061,\n",
              " 'G': 0.22301393749003728}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W1qMFGvrN3AB"
      },
      "source": [
        "Example script usage ^^"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfBjjIh4M1_R"
      },
      "outputs": [],
      "source": [
        "#!cd ML4RG-2023-project && python main.py --test --fasta ../Homo_sapiens_3prime_UTR.fa --species_list 240_species.txt --output_dir ./test --model_weight ../MLM_mammals_species_aware_5000_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "6UHmq-xyfO05",
        "outputId": "88fd89c0-5a44-4208-f7d2-58dd4ea38b14"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>3-UTR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CCCCCAGAACCAGTGGGACAAACTGCCTCCTGGAGGTTTTTAGAAA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TATTGAGCCCTCAGAGAGTCCACAGTCCCTCCTCTCAGTTCAGTCT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TATTCATTCCAACTGCTGCCCCTCTGTCTGCCTGGCTGAGATGCAT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AACGGTGCGTTTGGCCAAAAAGAATCTGCATTTAGCACAAAAAAAA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TAGTTTCTAACTGTCGGACCCGTCTGTAAACCAAGGACTATGAATA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1809</th>\n",
              "      <td>AGCAAGCATTGAAAATAATAGTTATTGCATACCAATCCTTGTTTGC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1810</th>\n",
              "      <td>AGCAAGCATTGAAAATAATAGTTATTGCATACCAATCCTTGTTTGC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1811</th>\n",
              "      <td>GCCTACTTCATCTCAGGACCCGCCCAAGAGTGGCCGCGGCTTTGGG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1812</th>\n",
              "      <td>TTGTCAGTCTGTCTGCTCAGGACACAAGAACTAAGGGGCAACAAAT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1813</th>\n",
              "      <td>CTTTATAGTGGCACAAACGCTTCAGAGACACACAATTATAAGAGAC...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1814 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  3-UTR\n",
              "0     CCCCCAGAACCAGTGGGACAAACTGCCTCCTGGAGGTTTTTAGAAA...\n",
              "1     TATTGAGCCCTCAGAGAGTCCACAGTCCCTCCTCTCAGTTCAGTCT...\n",
              "2     TATTCATTCCAACTGCTGCCCCTCTGTCTGCCTGGCTGAGATGCAT...\n",
              "3     AACGGTGCGTTTGGCCAAAAAGAATCTGCATTTAGCACAAAAAAAA...\n",
              "4     TAGTTTCTAACTGTCGGACCCGTCTGTAAACCAAGGACTATGAATA...\n",
              "...                                                 ...\n",
              "1809  AGCAAGCATTGAAAATAATAGTTATTGCATACCAATCCTTGTTTGC...\n",
              "1810  AGCAAGCATTGAAAATAATAGTTATTGCATACCAATCCTTGTTTGC...\n",
              "1811  GCCTACTTCATCTCAGGACCCGCCCAAGAGTGGCCGCGGCTTTGGG...\n",
              "1812  TTGTCAGTCTGTCTGCTCAGGACACAAGAACTAAGGGGCAACAAAT...\n",
              "1813  CTTTATAGTGGCACAAACGCTTCAGAGACACACAATTATAAGAGAC...\n",
              "\n",
              "[1814 rows x 1 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_path = 'test_df.pickle'\n",
        "if os.path.exists(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        train_df = pickle.load(f)\n",
        "else:\n",
        "    # load the fasta file and select the train data\n",
        "    fasta_file = \"../../../test/Homo_sapiens_3prime_UTR.fa\"\n",
        "    sequences = []\n",
        "    for s in SeqIO.parse(fasta_file, \"fasta\"):\n",
        "        sequences.append(str(s.seq).upper())\n",
        "    # get the train fraction\n",
        "    val_fraction = 0.1\n",
        "    N_train = int(len(sequences)*(1-val_fraction))\n",
        "    test_data = sequences[N_train:]\n",
        "    # store it as a dataframe\n",
        "    test_df = pd.DataFrame({'3-UTR':test_data})\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(test_df, f)\n",
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "fmffSnZkfqSw",
        "outputId": "5934c70e-252c-4aba-ed39-334efce50f57"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>3-UTR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ATCTTATATAACTGTGAGATTAATCTCAGATAATGACACAAAATAT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GGTTGCCGGGGGTAGGGGTGGGGCCACACAAATCTCCAGGAGCCAC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GGCAGCCCATCTGGGGGGCCTGTAGGGGCTGCCGGGCTGGTGGCCA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CCCACCTACCACCAGAGGCCTGCAGCCTCCCACATGCCTTAAGGGG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TGGCCGCGGTGAGGTGGGTTCTCAGGACCACCCTCGCCAAGCTCCA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16315</th>\n",
              "      <td>CCGTATGAAGATGTCCTGTTAAATTTACAACACTAACGATGTAGAC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16316</th>\n",
              "      <td>ACACACCCCCGAAAAACACAAGACCGACCCAAAATCTAGAGGAAAG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16317</th>\n",
              "      <td>AGAAGCTAAAAGGAAAGAAAATAAATCTATCAAAATTACCCTAAAC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16318</th>\n",
              "      <td>CTTCACTTTTGGGCTCAAGGACTGTGTGAACCAACAAGGGGCCAGT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16319</th>\n",
              "      <td>TAGACAATGAGCTGCGAAAAGACTCCTGGTTCCCCTGTTGATTTGT...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16320 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   3-UTR\n",
              "0      ATCTTATATAACTGTGAGATTAATCTCAGATAATGACACAAAATAT...\n",
              "1      GGTTGCCGGGGGTAGGGGTGGGGCCACACAAATCTCCAGGAGCCAC...\n",
              "2      GGCAGCCCATCTGGGGGGCCTGTAGGGGCTGCCGGGCTGGTGGCCA...\n",
              "3      CCCACCTACCACCAGAGGCCTGCAGCCTCCCACATGCCTTAAGGGG...\n",
              "4      TGGCCGCGGTGAGGTGGGTTCTCAGGACCACCCTCGCCAAGCTCCA...\n",
              "...                                                  ...\n",
              "16315  CCGTATGAAGATGTCCTGTTAAATTTACAACACTAACGATGTAGAC...\n",
              "16316  ACACACCCCCGAAAAACACAAGACCGACCCAAAATCTAGAGGAAAG...\n",
              "16317  AGAAGCTAAAAGGAAAGAAAATAAATCTATCAAAATTACCCTAAAC...\n",
              "16318  CTTCACTTTTGGGCTCAAGGACTGTGTGAACCAACAAGGGGCCAGT...\n",
              "16319  TAGACAATGAGCTGCGAAAAGACTCCTGGTTCCCCTGTTGATTTGT...\n",
              "\n",
              "[16320 rows x 1 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_path = 'train_df.pickle'\n",
        "if os.path.exists(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        train_df = pickle.load(f)\n",
        "else:\n",
        "    # load the fasta file and select the train data\n",
        "    fasta_file = \"../../../test/Homo_sapiens_3prime_UTR.fa\"\n",
        "    sequences = []\n",
        "    for s in SeqIO.parse(fasta_file, \"fasta\"):\n",
        "        sequences.append(str(s.seq).upper())\n",
        "    # get the train fraction\n",
        "    val_fraction = 0.1\n",
        "    N_train = int(len(sequences)*(1-val_fraction))\n",
        "    train_data = sequences[:N_train]\n",
        "    # store it as a dataframe\n",
        "    train_df = pd.DataFrame({'3-UTR':train_data})\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(train_df, f)\n",
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR-13KWugbg5",
        "outputId": "4d3f6d40-7906-45ea-f9e5-061cb5a4232d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/16320 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16320/16320 [01:05<00:00, 250.06it/s]\n"
          ]
        }
      ],
      "source": [
        "file_path = 'kmer_train.pickle'\n",
        "if os.path.exists(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        kmer_train = pickle.load(f)\n",
        "else:\n",
        "    # get the frequency counts of all motifs till 11mer\n",
        "    kmer_train = KmerCountNew(2,pseudocount=0.1)\n",
        "    kmer_train.compute_counts(train_df['3-UTR'])\n",
        "    kmer_train.kmer_counts_dict\n",
        "\n",
        "    # save dictionary pickle file\n",
        "    with open('kmer_train.pickle', 'wb') as f:\n",
        "        pickle.dump(kmer_train, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zCB_kARvtzKl"
      },
      "outputs": [],
      "source": [
        "dinuc_dist = np.array([[[0.26743808301046024,0.21973121381119634, 0.22301393749003728, 0.2898167656883061],\n",
        "        [0.        , 0.        , 0.        , 0.        ],\n",
        "        [0.        , 0.        , 0.        , 0.        ],\n",
        "        [0.        , 0.        , 0.        , 0.        ]],\n",
        "\n",
        "       [[0.2968737832744875, 0.18507058520226632, 0.26581813454136444,0.26581813454136444],\n",
        "        [0.32053421022722217, 0.2803858410399341, 0.0554500543745703, 0.34362989435827346],\n",
        "        [0.26000757243673117, 0.2138329457921364, 0.26097487205728753, 0.24694501885793302],\n",
        "        [0.20207800866762973, 0.20690293271757126, 0.27748861612369985, 0.3135304424910991]]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "c6ujG9KfR9YC"
      },
      "outputs": [],
      "source": [
        "chain = MarkovChainNew(kmer_train, dinuc_dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eZqho3GSQN_",
        "outputId": "c45130a3-39df-4b20-baf4-f8fb5c490f31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[0.26743808, 0.21973121, 0.22301394, 0.28981677],\n",
              "        [0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        ]],\n",
              "\n",
              "       [[0.29687378, 0.18507059, 0.26581813, 0.26581813],\n",
              "        [0.32053421, 0.28038584, 0.05545005, 0.34362989],\n",
              "        [0.26000757, 0.21383295, 0.26097487, 0.24694502],\n",
              "        [0.20207801, 0.20690293, 0.27748862, 0.31353044]]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.markov_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwhJlh8mUcgM",
        "outputId": "9558b16f-27ff-4f27-8a8c-1f3dcc4d952e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.26743808, 0.21973121, 0.22301394, 0.28981677],\n",
              "       [0.29687378, 0.18507059, 0.26581813, 0.26581813],\n",
              "       [0.29687378, 0.18507059, 0.26581813, 0.26581813],\n",
              "       [0.29687378, 0.18507059, 0.26581813, 0.26581813],\n",
              "       [0.32053421, 0.28038584, 0.05545005, 0.34362989]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.impute_for_seq(\"AAACT\", 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_LEJKkAugzF8"
      },
      "outputs": [],
      "source": [
        "markov_model = MarkovModelNew(\n",
        "    kmer_train,\n",
        "    markov_matrix_path=\"markov_model.npy\",\n",
        "    order=1,\n",
        "    bidirectional=False,\n",
        "    test_df_path='test_df.pickle',\n",
        "    dinuc_dist = dinuc_dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IiUmjmZcg3b1"
      },
      "outputs": [],
      "source": [
        "markov_model.test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LL9tNZ8ZXFmx",
        "outputId": "c4708ede-755a-4c5b-a698-09e8992629d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "j2tttZdnW-U7"
      },
      "outputs": [],
      "source": [
        "!cp -r \"/content/prbs.pt\" \"/content/drive/MyDrive/MLRG2023\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXm14Qce89i4"
      },
      "outputs": [],
      "source": [
        "class SeqDataset(Dataset):\n",
        "\n",
        "    def __init__(self, fasta_fa, seq_df, transform):\n",
        "\n",
        "        self.fasta = pysam.FastaFile(fasta_fa)\n",
        "\n",
        "        self.seq_df = seq_df\n",
        "        self.transform = transform\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.seq_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        seq = self.fasta.fetch(self.seq_df.iloc[idx].seq_name).upper()\n",
        "        #print(seq)\n",
        "\n",
        "        species_label = self.seq_df.iloc[idx].species_label\n",
        "        #print(species_label)\n",
        "        motifs = {\"GTATG\":1}\n",
        "\n",
        "        masked_sequence, target_labels_masked, target_labels, mask, _ = self.transform(seq, motifs = motifs)\n",
        "\n",
        "        masked_sequence = (masked_sequence, species_label)\n",
        "\n",
        "        return masked_sequence, target_labels_masked, target_labels\n",
        "\n",
        "    def close(self):\n",
        "        self.fasta.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pn3Q2CT9Cco5"
      },
      "source": [
        "# Read the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2HLxQAuAIyF"
      },
      "outputs": [],
      "source": [
        "fasta_fa = \"./Homo_sapiens_3prime_UTR.fa\"\n",
        "species_list = \"ML4RG-2023-project/240_species.txt\"\n",
        "\n",
        "seq_df = pd.read_csv(fasta_fa + '.fai', header=None, sep='\\t', usecols=[0], names=['seq_name'])\n",
        "seq_df['species_name'] = seq_df.seq_name.apply(lambda x:x.split(':')[1])\n",
        "species_encoding = pd.read_csv(species_list, header=None).squeeze().to_dict()\n",
        "species_encoding = {species:idx for idx,species in species_encoding.items()}\n",
        "species_encoding['Homo_sapiens'] = species_encoding['Pan_troglodytes']\n",
        "seq_df['species_label'] = seq_df.species_name.map(species_encoding)\n",
        "seq_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-vMMPNsDE47"
      },
      "outputs": [],
      "source": [
        "# Motif:id\n",
        "motifs = {\"GTATG\":1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73adEDPTGeAF"
      },
      "outputs": [],
      "source": [
        "kseq_len = 5000\n",
        "total_len = 5000\n",
        "\n",
        "#\n",
        "seq_transform = sequence_encoders.RollingMasker(mask_stride=50, frame=0)\n",
        "\n",
        "\n",
        "test_dataset = SeqDataset(fasta_fa, seq_df, transform = seq_transform)\n",
        "test_dataloader = DataLoader(dataset = test_dataset, batch_size = 1, num_workers = 1, collate_fn = None, shuffle = False)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "niH8MWiYHOh5"
      },
      "source": [
        "# Load the model\n",
        "## Model params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqdhSyBUHM12"
      },
      "outputs": [],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device('cuda')\n",
        "d_model = 128\n",
        "n_layers = 4\n",
        "dropout = 0.\n",
        "learn_rate = 1e-4\n",
        "weight_decay = 0.\n",
        "output_dir = \"./test/\"\n",
        "get_embeddings = True\n",
        "save_at = []"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1aIpGqFHaZY"
      },
      "source": [
        "## Model\n",
        "If the following line fails:\n",
        "\n",
        "```\n",
        "model = model.to(device)\n",
        "```\n",
        "Either use:\n",
        "\n",
        "\n",
        "```\n",
        "device = torch.device(\"cpu\")\n",
        "```\n",
        "Or go to Runtime -> change runtime type -> Hardware Accellerator 'GPU'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCp_1J1HHXIZ"
      },
      "outputs": [],
      "source": [
        "species_encoder = SpecAdd(embed = True, encoder = 'label', d_model = d_model)\n",
        "\n",
        "model = DSSResNetEmb(d_input = 5, d_output = 5, d_model = d_model, n_layers = n_layers, dropout = dropout, embed_before = True, species_encoder = species_encoder)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "model_params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "optimizer = torch.optim.Adam(model_params, lr = learn_rate, weight_decay = weight_decay)\n",
        "\n",
        "last_epoch = 0\n",
        "model_weight = \"MLM_mammals_species_aware_5000_weights\"\n",
        "model.load_state_dict(torch.load(model_weight))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHOVe0-BHb2j",
        "outputId": "eeedfe89-80aa-4841-d725-3cbbc983ca2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023/06/10-19:20:01]- Test/Inference...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/./ML4RG-2023-project/helpers/train_eval.py:96: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  species_label = torch.tensor(species_label).long().to(device)\n",
            "/content/./ML4RG-2023-project/models/dss.py:335: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at ../aten/src/ATen/native/Copy.cpp:276.)\n",
            "  return einsum('chn,hnl->chl', W, S).float(), state                   # [C H L]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1338: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.\n",
            "  warnings.warn(\"dropout2d: Received a 3D input to dropout2d and assuming that channel-wise \"\n"
          ]
        }
      ],
      "source": [
        "predictions_dir = os.path.join(output_dir, 'predictions') #dir to save predictions\n",
        "weights_dir = os.path.join(output_dir, 'weights') #dir to save model weights at save_at epochs\n",
        "if save_at:\n",
        "    os.makedirs(weights_dir, exist_ok = True)\n",
        "\n",
        "def metrics_to_str(metrics):\n",
        "    loss, total_acc, masked_acc = metrics\n",
        "    return f'loss: {loss:.4}, total acc: {total_acc:.3f}, masked acc: {masked_acc:.3f}'\n",
        "\n",
        "from helpers.misc import print    #print function that displays time\n",
        "print(f'Test/Inference...')\n",
        "\n",
        "test_metrics, test_embeddings =  train_eval.model_eval(model, optimizer, test_dataloader, device,\n",
        "                                                          get_embeddings = get_embeddings, silent = True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yvk3vrQBIoiX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
